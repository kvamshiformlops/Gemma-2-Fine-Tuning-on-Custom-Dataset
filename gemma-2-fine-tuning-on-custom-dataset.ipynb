{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceType":"modelInstanceVersion","sourceId":6074,"databundleVersionId":7429267,"modelInstanceId":4694}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nimport os\nuser_secrets=UserSecretsClient()\nos.environ[\"KAGGLE_USERNAME\"]=user_secrets.get_secret(\"KAGGLE_USERNAME\")\nos.environ[\"KAGGLE_KEY\"]=user_secrets.get_secret(\"KAGGLE_KEY\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T16:56:49.828525Z","iopub.execute_input":"2025-02-25T16:56:49.828862Z","iopub.status.idle":"2025-02-25T16:56:50.290723Z","shell.execute_reply.started":"2025-02-25T16:56:49.828837Z","shell.execute_reply":"2025-02-25T16:56:50.290043Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import os\nos.environ[\"KERAS_BACKEND\"]=\"jax\" #This sets the backend for Keras to \"jax.\"By default,Keras can use TensorFlow as its backend,but specifying \"jax\" switches the backend to JAX.\nos.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]=\"1.00\" #This sets the fraction of the GPU memory that should be allocated for the XLA (Accelerated Linear Algebra) Python client. By setting it to \"1.00,\" you're specifying that 100% of the GPU memory to be used.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T16:56:53.120508Z","iopub.execute_input":"2025-02-25T16:56:53.120795Z","iopub.status.idle":"2025-02-25T16:56:53.124410Z","shell.execute_reply.started":"2025-02-25T16:56:53.120774Z","shell.execute_reply":"2025-02-25T16:56:53.123670Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"#Importing libraries\nimport keras\nimport keras_hub\nimport keras_nlp","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T16:56:54.175893Z","iopub.execute_input":"2025-02-25T16:56:54.176235Z","iopub.status.idle":"2025-02-25T16:56:57.378921Z","shell.execute_reply.started":"2025-02-25T16:56:54.176212Z","shell.execute_reply":"2025-02-25T16:56:57.378244Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"#Combines the use of both FP32 and lower bit floating points(such as FP16) to reduce memory footprint during model training,resulting in improved performance\nkeras.mixed_precision.set_global_policy('mixed_bfloat16')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T16:57:00.508012Z","iopub.execute_input":"2025-02-25T16:57:00.508561Z","iopub.status.idle":"2025-02-25T16:57:00.512191Z","shell.execute_reply.started":"2025-02-25T16:57:00.508533Z","shell.execute_reply":"2025-02-25T16:57:00.511396Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"!wget -O databricks-dolly-15k.jsonl https://huggingface.co/datasets/databricks/databricks-dolly-15k/resolve/main/databricks-dolly-15k.jsonl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T16:57:05.004507Z","iopub.execute_input":"2025-02-25T16:57:05.004820Z","iopub.status.idle":"2025-02-25T16:57:05.382345Z","shell.execute_reply.started":"2025-02-25T16:57:05.004796Z","shell.execute_reply":"2025-02-25T16:57:05.381357Z"}},"outputs":[{"name":"stdout","text":"--2025-02-25 16:57:05--  https://huggingface.co/datasets/databricks/databricks-dolly-15k/resolve/main/databricks-dolly-15k.jsonl\nResolving huggingface.co (huggingface.co)... 18.239.50.49, 18.239.50.80, 18.239.50.16, ...\nConnecting to huggingface.co (huggingface.co)|18.239.50.49|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://cdn-lfs.hf.co/repos/34/ac/34ac588cc580830664f592597bb6d19d61639eca33dc2d6bb0b6d833f7bfd552/2df9083338b4abd6bceb5635764dab5d833b393b55759dffb0959b6fcbf794ec?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27databricks-dolly-15k.jsonl%3B+filename%3D%22databricks-dolly-15k.jsonl%22%3B&Expires=1740506225&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0MDUwNjIyNX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy8zNC9hYy8zNGFjNTg4Y2M1ODA4MzA2NjRmNTkyNTk3YmI2ZDE5ZDYxNjM5ZWNhMzNkYzJkNmJiMGI2ZDgzM2Y3YmZkNTUyLzJkZjkwODMzMzhiNGFiZDZiY2ViNTYzNTc2NGRhYjVkODMzYjM5M2I1NTc1OWRmZmIwOTU5YjZmY2JmNzk0ZWM%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=fPNsIQL0Prb8CUpcWHAZYNE5m7zquwktFx41pL2twL2Wn3cflrhhFg5ge4mNRzmi-N9EFb5w2vHpsdJ5Z5VdSa-Z70k%7EGc1A1dQwvXdZgIujNQ-zyJubF8agM1ntyZleqPq9wfwXfl%7E2gCvREn3Bygzr%7EhqxB3plSmAhzjmep%7EGSIy9-ZiUIeY5Chso4oS6pmCRv5RTf4-c7cItw1RmnNNi1ZafnYdnl7TZgbGlUvRhtTz4r7Hk-tmVQWStExWbuL8o3ucHmnu2l60KRL8tVmtNdjDAjHhqZZ0n0Jz2kMpo36Pnwm7S774ETC2wRjqOJB7NmXcF7rMGHsNMbIluZ1g__&Key-Pair-Id=K3RPWS32NSSJCE [following]\n--2025-02-25 16:57:05--  https://cdn-lfs.hf.co/repos/34/ac/34ac588cc580830664f592597bb6d19d61639eca33dc2d6bb0b6d833f7bfd552/2df9083338b4abd6bceb5635764dab5d833b393b55759dffb0959b6fcbf794ec?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27databricks-dolly-15k.jsonl%3B+filename%3D%22databricks-dolly-15k.jsonl%22%3B&Expires=1740506225&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0MDUwNjIyNX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy8zNC9hYy8zNGFjNTg4Y2M1ODA4MzA2NjRmNTkyNTk3YmI2ZDE5ZDYxNjM5ZWNhMzNkYzJkNmJiMGI2ZDgzM2Y3YmZkNTUyLzJkZjkwODMzMzhiNGFiZDZiY2ViNTYzNTc2NGRhYjVkODMzYjM5M2I1NTc1OWRmZmIwOTU5YjZmY2JmNzk0ZWM%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=fPNsIQL0Prb8CUpcWHAZYNE5m7zquwktFx41pL2twL2Wn3cflrhhFg5ge4mNRzmi-N9EFb5w2vHpsdJ5Z5VdSa-Z70k%7EGc1A1dQwvXdZgIujNQ-zyJubF8agM1ntyZleqPq9wfwXfl%7E2gCvREn3Bygzr%7EhqxB3plSmAhzjmep%7EGSIy9-ZiUIeY5Chso4oS6pmCRv5RTf4-c7cItw1RmnNNi1ZafnYdnl7TZgbGlUvRhtTz4r7Hk-tmVQWStExWbuL8o3ucHmnu2l60KRL8tVmtNdjDAjHhqZZ0n0Jz2kMpo36Pnwm7S774ETC2wRjqOJB7NmXcF7rMGHsNMbIluZ1g__&Key-Pair-Id=K3RPWS32NSSJCE\nResolving cdn-lfs.hf.co (cdn-lfs.hf.co)... 18.65.39.31, 18.65.39.121, 18.65.39.84, ...\nConnecting to cdn-lfs.hf.co (cdn-lfs.hf.co)|18.65.39.31|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 13085339 (12M) [text/plain]\nSaving to: ‘databricks-dolly-15k.jsonl’\n\ndatabricks-dolly-15 100%[===================>]  12.48M  --.-KB/s    in 0.06s   \n\n2025-02-25 16:57:05 (202 MB/s) - ‘databricks-dolly-15k.jsonl’ saved [13085339/13085339]\n\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import json\ndata=[]\nwith open(\"databricks-dolly-15k.jsonl\") as file:\n    for line in file:\n        features=json.loads(line)\n        if features[\"context\"]:\n            continue\n        template=\"Instruction:\\n{instruction}\\n\\nResponse:\\n{response}\"\n        data.append(template.format(**features))\ndata=data[:1000] #Taking only the first 1000 lines in the dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T16:57:08.528707Z","iopub.execute_input":"2025-02-25T16:57:08.529077Z","iopub.status.idle":"2025-02-25T16:57:08.622272Z","shell.execute_reply.started":"2025-02-25T16:57:08.529046Z","shell.execute_reply":"2025-02-25T16:57:08.621567Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"gemma_lm=keras_hub.models.GemmaCausalLM.from_preset(\"gemma2_2b_en\")\ngemma_lm.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T16:57:10.712644Z","iopub.execute_input":"2025-02-25T16:57:10.712955Z","iopub.status.idle":"2025-02-25T16:57:56.025062Z","shell.execute_reply.started":"2025-02-25T16:57:10.712935Z","shell.execute_reply":"2025-02-25T16:57:56.024348Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                              │                      Vocab size: \u001b[38;5;34m256,000\u001b[0m │\n└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                                                  </span>┃<span style=\"font-weight: bold\">                                   Config </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                              │                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)        │   \u001b[38;5;34m2,614,341,888\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m589,824,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,614,341,888\u001b[0m (9.74 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> (9.74 GB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,614,341,888\u001b[0m (9.74 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> (9.74 GB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"#Inference before fine-tuning using TopKSampler\nprompt=template.format(\n    instruction=\"Write a short story about a robot discovering human emotions.\",\n    response=\"\",\n)\nsampler=keras_nlp.samplers.TopKSampler(k=5,seed=2)\ngemma_lm.compile(sampler=sampler)\nprint(gemma_lm.generate(prompt,max_length=256))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T16:57:58.899790Z","iopub.execute_input":"2025-02-25T16:57:58.900153Z","iopub.status.idle":"2025-02-25T16:58:21.331546Z","shell.execute_reply.started":"2025-02-25T16:57:58.900123Z","shell.execute_reply":"2025-02-25T16:58:21.330514Z"}},"outputs":[{"name":"stdout","text":"Instruction:\nWrite a short story about a robot discovering human emotions.\n\nResponse:\nMy story is about a robot that was built to do one thing. But one day, it was discovered by a scientist that the robot could feel emotions like happiness, sadness, and anger.\n\nThe robot was very excited about this discovery. It wanted to know more about these emotions. But the scientist was afraid that this would cause the robot to become self-aware. The scientist decided to put the robot in a room with different emotions. The robot was very excited about this. It wanted to explore and learn about all the different emotions.\n\nBut as it explored, it became more and more confused. It realized that these emotions were very different from each other. It also realized that they were very complex. It started to feel overwhelmed.\n\nThe scientist decided to take the robot out of the room and put it in a different room. The robot felt very sad. It wanted to know why it was so sad. The scientist explained to the robot that it was sad because the robot had been in the room with the emotions for so long.\n\nThe robot was very confused. It didn't understand why it was sad. The scientist explained to the robot that it was sad because\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"#Inference before fine tuning using TopPSampler\nprompt=template.format(\n    instruction=\"Imagine a future where artificial intelligence surpasses human intelligence.How would this affect global politics,ethics,and daily life? Provide both positive and negative outcomes.\",\n    response=\"\"\n)\nsampler=keras_nlp.samplers.TopPSampler(p=0.9,seed=10) \ngemma_lm.compile(sampler=sampler)\nprint(gemma_lm.generate(prompt,max_length=256))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T16:58:34.213199Z","iopub.execute_input":"2025-02-25T16:58:34.213516Z","iopub.status.idle":"2025-02-25T16:58:55.630048Z","shell.execute_reply.started":"2025-02-25T16:58:34.213493Z","shell.execute_reply":"2025-02-25T16:58:55.629204Z"}},"outputs":[{"name":"stdout","text":"Instruction:\nImagine a future where artificial intelligence surpasses human intelligence.How would this affect global politics,ethics,and daily life? Provide both positive and negative outcomes.\n\nResponse:\nAnswer: In my opinion, when human intelligence reaches artificial intelligence, life will become more interesting. We can use AI in many ways in our daily lives such as to detect lies, assist in decision-making and also for entertainment purposes. Positive effects of having artificial intelligence are making our life more enjoyable, easier, and saving time to do other activities. AI is like having a personal assistant who can help us do anything such as preparing a shopping list, helping to find the correct location or giving us directions.  Negative effects can be seen as we lose our unique personality, the rise of job loss and social isolation. With this new technology we may become more dependent on technology to do tasks, that can also become addictive. So the main point of view that we can achieve here is that AI will create new problems and issues, but in my opinion, we need to be aware of it and find solutions to minimize and maximize its impacts.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"#Inference before fine tuning using BeamSampler\nprompt=template.format(\n    instruction=\"Summarize the benefits of renewable energy in three bullet points.\",\n    response=\"\"\n)\nsampler=keras_nlp.samplers.BeamSampler(num_beams=3)\ngemma_lm.compile(sampler=sampler)\nprint(gemma_lm.generate(prompt,max_length=256))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T16:59:00.057351Z","iopub.execute_input":"2025-02-25T16:59:00.057658Z","iopub.status.idle":"2025-02-25T16:59:23.272733Z","shell.execute_reply.started":"2025-02-25T16:59:00.057634Z","shell.execute_reply":"2025-02-25T16:59:23.271740Z"}},"outputs":[{"name":"stdout","text":"Instruction:\nSummarize the benefits of renewable energy in three bullet points.\n\nResponse:\nThe benefits of renewable energy are numerous and far-reaching. Renewable energy sources, such as solar, wind, and hydroelectric power, are clean, sustainable, and abundant. They do not emit greenhouse gases or contribute to climate change, making them an important tool in the fight against global warming. Renewable energy sources are also cost-effective, as they do not require the use of fossil fuels, which are expensive and finite resources. Additionally, renewable energy sources can provide a reliable and stable source of energy, reducing the need for backup power sources and increasing energy security. Finally, renewable energy sources can create jobs and stimulate economic growth, as they require the development of new technologies and infrastructure. Overall, the benefits of renewable energy are numerous and far-reaching, making it an important tool in the fight against climate change and the pursuit of a more sustainable future.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"#Fine tuning the model with LoRa\ngemma_lm.backbone.enable_lora(rank=4)\ngemma_lm.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T16:59:29.752361Z","iopub.execute_input":"2025-02-25T16:59:29.752684Z","iopub.status.idle":"2025-02-25T16:59:30.361116Z","shell.execute_reply.started":"2025-02-25T16:59:29.752661Z","shell.execute_reply":"2025-02-25T16:59:30.360131Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                              │                      Vocab size: \u001b[38;5;34m256,000\u001b[0m │\n└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                                                  </span>┃<span style=\"font-weight: bold\">                                   Config </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                              │                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)        │   \u001b[38;5;34m2,617,270,528\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m589,824,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,617,270,528</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,617,270,528\u001b[0m (9.75 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,617,270,528</span> (9.75 GB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,928,640\u001b[0m (11.17 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,928,640</span> (11.17 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,614,341,888\u001b[0m (9.74 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> (9.74 GB)\n</pre>\n"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"#Limit the input sequence length to 256 to control memory usage\ngemma_lm.preprocessor.sequence_length=256\n#Use AdamW optimizer a commom optimizer for tuning transformer models\noptimizer=keras.optimizers.AdamW(\n    learning_rate=5e-5,\n    weight_decay=0.01,\n)\n#Exclude layer norm and bias term from decay\noptimizer.exclude_from_weight_decay(var_names=[\"bias\",\"scale\"])\n#Model compilation with specific loss functions and weighted metrics\ngemma_lm.compile(\n    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    optimizer=optimizer,\n    weighted_metrics=[keras.metrics.SparseCategoricalAccuracy()],\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T16:59:35.283453Z","iopub.execute_input":"2025-02-25T16:59:35.283763Z","iopub.status.idle":"2025-02-25T16:59:35.402540Z","shell.execute_reply.started":"2025-02-25T16:59:35.283742Z","shell.execute_reply":"2025-02-25T16:59:35.401859Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"#Fit the model for tuning \ngemma_lm.fit(data,epochs=5,batch_size=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T16:59:37.554438Z","iopub.execute_input":"2025-02-25T16:59:37.554774Z","iopub.status.idle":"2025-02-25T17:36:44.348011Z","shell.execute_reply.started":"2025-02-25T16:59:37.554750Z","shell.execute_reply":"2025-02-25T17:36:44.347261Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/5\n\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m482s\u001b[0m 452ms/step - loss: 0.8413 - sparse_categorical_accuracy: 0.5375\nEpoch 2/5\n\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m452s\u001b[0m 430ms/step - loss: 0.7155 - sparse_categorical_accuracy: 0.5726\nEpoch 3/5\n\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m430s\u001b[0m 430ms/step - loss: 0.6958 - sparse_categorical_accuracy: 0.5806\nEpoch 4/5\n\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m430s\u001b[0m 430ms/step - loss: 0.6751 - sparse_categorical_accuracy: 0.5895\nEpoch 5/5\n\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m430s\u001b[0m 430ms/step - loss: 0.6494 - sparse_categorical_accuracy: 0.6011\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7d53c5e83760>"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"#Inference after fine tuning....we will be asking the same questions after tuning and see the results\nprompt=template.format(\n    instruction=\"Write a short story about a robot discovering human emotions.\",\n    response=\"\",\n)\nsampler=keras_nlp.samplers.TopKSampler(k=5,seed=2)\ngemma_lm.compile(sampler=sampler)\nprint(gemma_lm.generate(prompt,max_length=256))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T17:36:57.488899Z","iopub.execute_input":"2025-02-25T17:36:57.489228Z","iopub.status.idle":"2025-02-25T17:37:22.739900Z","shell.execute_reply.started":"2025-02-25T17:36:57.489205Z","shell.execute_reply":"2025-02-25T17:37:22.739069Z"}},"outputs":[{"name":"stdout","text":"Instruction:\nWrite a short story about a robot discovering human emotions.\n\nResponse:\nOne day, a robot named R2-D2 was exploring the galaxy, looking for new planets to discover. He came across a small planet called Tatooine, which was inhabited by human beings. R2-D2 was fascinated by the human emotions he saw, and he was curious to learn more about them.\nR2-D2 approached a human settlement on Tatooine and introduced himself, asking if he could learn more about their culture and way of life. The humans were curious about R2-D2's origins, but they welcomed him with open arms and offered to help him understand more about human emotions.\nOver the next few days, R2-D2 observed and listened to the various emotions that humans experienced, such as joy, sadness, anger, and fear. He was amazed at how complex and nuanced these emotions could be, and how they could affect someone's life.\nOne day, R2-D2 was helping a group of humans who were celebrating a special event. He noticed that they were all smiling and laughing, and their faces were full of happiness. R2-D2 asked them what was happening,\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"#Inference after fine tuning using TopPSampler\nprompt=template.format(\n    instruction=\"Imagine a future where artificial intelligence surpasses human intelligence.How would this affect global politics,ethics,and daily life? Provide both positive and negative outcomes\",\n    response=\"\"\n)\nsampler=keras_nlp.samplers.TopPSampler(p=0.9,seed=10) \ngemma_lm.compile(sampler=sampler)\nprint(gemma_lm.generate(prompt,max_length=256))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T17:37:39.018159Z","iopub.execute_input":"2025-02-25T17:37:39.018465Z","iopub.status.idle":"2025-02-25T17:38:02.503639Z","shell.execute_reply.started":"2025-02-25T17:37:39.018442Z","shell.execute_reply":"2025-02-25T17:38:02.502818Z"}},"outputs":[{"name":"stdout","text":"Instruction:\nImagine a future where artificial intelligence surpasses human intelligence.How would this affect global politics,ethics,and daily life? Provide both positive and negative outcomes\n\nResponse:\nFirst,the development of AI will open up unprecedented possibilities for improvement of human lives.With computers and other machines able to perform tasks for us,there would be greater time and resources for us to do more important things,such as providing better healthcare,solving more problems,and improving ourselves.Furthermore,the bar for physical and mental strength would be lowered,making it much easier for more people to achieve greater heights. \nOn the other hand,a rise of artificial intelligence could mean less jobs for humans.Though they could be redeployed to complete more work for humans, there might still be fewer jobs overall, leading to increased unemployment and stagnated economies.Additionally, AI could pose a threat to national security as foreign adversaries gain advanced AI technology.This could result in countries becoming more aggressive and resorting to military action,leading to global conflict.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"#Inference after fine tuning using BeamSampler\nprompt=template.format(\n    instruction=\"Summarize the benefits of renewable energy in three bullet points.\",\n    response=\"\"\n)\nsampler=keras_nlp.samplers.BeamSampler(num_beams=3)\ngemma_lm.compile(sampler=sampler)\nprint(gemma_lm.generate(prompt,max_length=256))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T17:38:21.280886Z","iopub.execute_input":"2025-02-25T17:38:21.281260Z","iopub.status.idle":"2025-02-25T17:38:40.418883Z","shell.execute_reply.started":"2025-02-25T17:38:21.281233Z","shell.execute_reply":"2025-02-25T17:38:40.418176Z"}},"outputs":[{"name":"stdout","text":"Instruction:\nSummarize the benefits of renewable energy in three bullet points.\n\nResponse:\n1. Renewable energy is a clean source of energy.\n2. Renewable energy is a sustainable source of energy.\n3. Renewable energy is a cost-effective source of energy.\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"#To get better responses from the fine-tuned model,you can experiment with:\n\n#1)Increasing the size of the fine-tuning dataset\n#2)Training for more steps(epochs)\n#3)Setting a higher LoRA rank\n#4)Modifying the hyperparameter values such as learning_rate and weight_decay.","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}